{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistical Learning\n",
    "\n",
    "It refers to a set of approaches for estimating $f$\n",
    "\n",
    "##### Why estimate $f$\n",
    "for Prediction and Inference \n",
    "\n",
    "##### Prediction\n",
    "\n",
    "$\\hat{Y} = \\hat{f}(X)$ where $\\hat{f}$ is the black box often we don't care about the form of $\\hat{f}$ , provided that it yields accurate results \n",
    "\n",
    "$X$ are set of inputs points and $\\hat{Y}$ is the predictioni for $Y$\n",
    "\n",
    "##### Reducible error \n",
    "$\\hat{f}$ will not be a perfect estimate and this inaccuracy will introduce some error. This is the *reducable* error as it can be improved by choosing the most appropriate learning technique for $f$\n",
    "\n",
    "##### Irreducible error \n",
    "Even if we get a perfect estimate for $f$, our prediction will have some error in it. This is because $Y$ is also a function of $\\epsilon$, which cannot be prediction by $X$. There variablity associated with $\\epsilon$ also affects the accuracy of our predictions. \n",
    "\n",
    "This is called *Irreducible error*\n",
    "\n",
    "Why cannot we reduce this error?\n",
    "\n",
    "    1.the quantity of $\\epsilon$ contain unmeasured variables that are useful in prediction $Y$. Since we don't measure them, $f$ cannot use for its prediction.\n",
    "    2.The  $\\epsilon$ may also contain unmeasurable variation. \n",
    " \n",
    "eg: risk of an adverse reaction for a given patient might vary at given time of the day, depending on various factors.\n",
    "\n",
    "$$ E(Y-\\hat{Y})^2 = E[f(X) + \\epsilon - \\hat{f}(X)]^2$$\n",
    "$$ =  [f(X) - \\hat{f}(X)]^2 + \\text{Var}(\\epsilon)$$\n",
    "\n",
    "$E(Y-\\hat{Y})^2$ is the average or expected value of the squared distance between the predicted and the actual value of $Y$\n",
    "\n",
    "\n",
    "##### Inference \n",
    "Understanding the way $Y$ is affected as $X_1,...,X_p$ change. we need understand the relationship between X and Y and understand how $Y$ changes as a function of $X_1,...,X_p$. \n",
    "the function cannot be treated as black box. \n",
    "\n",
    "    1.Which predictors are associated with the response? \n",
    "    2.What is the relationship between the response and each predictor? \n",
    "    3.Can the relationship between Y and each predictor be adequately summarized by a linear equation or the relationship is more complicated? \n",
    "    \n",
    "    1.Which predictors contributed to a response? \n",
    "    2.Which predictos increased the sales ? \n",
    "    3 What is the percentage increase in the reponse variable with a given increase in the predictor? \n",
    "    \n",
    "    \n",
    "##### Prediction\n",
    "Getting an accurate model to predict the response using the predictors. The underlying fucntional relationship is not of importance here. \n",
    "\n",
    "##### how to estimate $f$?\n",
    "Apply statistical learning meethod to the training data in order to estimate the unknown function $f$. \n",
    "\n",
    "Most statistical learning methods are characterised as *parametric or non parametric*\n",
    "\n",
    "##### Parametric \n",
    "\n",
    ">We make an assumption about the functional form or shape. \n",
    "eg. $ f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2+ .... + \\beta_PX_P$.\n",
    "We assumed that f is a linear and only need to estimate P + 1 coefficients. \n",
    "\n",
    ">After the model is selected, we need a procedure that uses the training data to fit or train the model.  In case of linear model we need to estimate the $\\beta_0,\\beta_1....\\beta_p$\n",
    "\n",
    "The most common approach referred is ordinary least squares. \n",
    "\n",
    "\n",
    "disadvantages of parametric approach is \n",
    ">The model chosen will never match the true $f$\n",
    "\n",
    "##### Non-Parametric\n",
    "\n",
    "We do not make explicit assumptions about the functional form of $f$. Instead they seek an estimate of $f$ that is close to the data points as possible without being too rough or wiggly. \n",
    "\n",
    ">Advantage \n",
    "has a potential to fit a wider range of possible shapes for $f$. \n",
    "The model can estimate of $f$ will be very close to the true $f$\n",
    "\n",
    ">disadvantages\n",
    "They need large number of observations in order to provide the accurate estiamte for $f$\n",
    "\n",
    "If we are looking for inferring the relationship between predictors and repsonse variables, we would need a restrictive approach (eg: Linear model) \n",
    "\n",
    "if we are looking for prediction based on the input data and getting a response value, we would need a more flexible approach which can get accurate results \n",
    "\n",
    "\n",
    "side note: Info about scatter plots. if there are p data points in our observation. we can make $p(p-1)/2$ \n",
    "scatter plots\n",
    "\n",
    "\n",
    "##### Measuring the Quality of Fit \n",
    "\n",
    "##### Regression Setting\n",
    "\n",
    "$$ MSE = \\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{f}(x_i))^2 $$\n",
    "\n",
    "$$ Ave(y_0 - \\hat{f}(x_0))^2 $$\n",
    "\n",
    "In some setting when the test observations are available, the avg squared prediction error can be evaluated to get the best one with the smallest test MSE. \n",
    "\n",
    "when the test observations are not available, we need to select statistical learning method that minimizes  the training MSE. But this will not yield good predictions with a newer data. \n",
    "\n",
    "Regardless of overfitting or not, we almost always expect the training MSE to be smaller than the test MSe because most statistical learning methods either directly or indirectly seek to minimize the training MSE. \n",
    "\n",
    "Expected test MSE can be decomposed into sum of 3 quantities. \n",
    "\n",
    "##### Trade off between Bias and Variance \n",
    "\n",
    "$ E(y_0 - \\hat{f}(x_0))^2 = \\text{Var}(\\hat{f}(x_0)) + [\\text{Bias}(\\hat{f}(x_0))^2] + \\text{Var}(\\epsilon) $\n",
    "\n",
    "In order to minimize the expected test error, we need to select a statistical learning method that simultaneously achieves low variance and low bias. \n",
    "\n",
    "Variance refers to the amount by which $\\hat{f}$ would change if we estimated it using different training data set. \n",
    "\n",
    "Bias refers to the error introduced by approximating a real-life problem. \n",
    "\n",
    "More flexible methods will increase the variance and reduce the Bias and more restrictive models will have increase the Bias and reduce the variance. However, at some  point the flexiblity has little impact on the bias but starts to significantly increase the variance. When this happends the test MSE increases. \n",
    "\n",
    "Good test set performance of a statistical learning method requires low variance as well as low squared bias. This is referred to as a trade-off because it is easy to obtain a method with extremely low bias but high variance (for instance, by drawing a curve that passes through every\n",
    "single training observation) or a method with very low variance but high bias (by fitting a horizontal line to the data). The challenge lies in finding a method for which both the variance and the squared bias are low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Setting\n",
    "\n",
    "When the response variable is qualitative then we use classification setting. \n",
    "\n",
    "$$ \\hat{f} = \\frac{1}{n} \\sum_{i=1}^{n} I (y_i \\neq \\hat{y}_i) $$\n",
    "\n",
    "The equation computes the fraction of incorrect classifications and is referred to as training error rate. \n",
    "\n",
    "$\\text{Avg}(I(y_0 \\neq \\hat{y}_0)) $ is the test error rate where $\\hat{y}_0$ is the predicted class label that results from applying the classifer to the test observations with the predictor $x_0$ \n",
    "\n",
    "##### Bayes Classifier \n",
    "\n",
    "Classifier which assigns each observation to the most likely class given its predictor values. \n",
    "\n",
    "Assign a test observation with a predictor vector $x_0$ to the class $j$ for which $\\text{Pr}(Y = j|X = x_0)$ is the largest.\n",
    "\n",
    "Bayes decision boundary is one where the Probably is exactly 50%. \n",
    "\n",
    "Bayes error rate is $ 1 - E(\\underset{j}{\\text{max}} Pr(Y = j|X))$\n",
    "\n",
    "##### KNN \n",
    "\n",
    "A positive integer K is chosen along with a test observation $x_0$. \n",
    "the KNN identifies the K points in the training data set that is close to $x_0$, represented by a Neighbourhood $\\mathcal{N}_0$. It estimates the conditional probability of the class j as the fraction of points in $\\mathcal{N}_0$ whose response values equal $j$:\n",
    "$$ \\text{Pr}(Y = j|X = x_0) =  \\frac{1}{K}\\sum_{i\\in{\\mathcal{N}_0}}I(y_i = j)$$\n",
    "Finally KNN appplies bayes rule and classifies the test observation $x_0$ to the class with the largest probablity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
